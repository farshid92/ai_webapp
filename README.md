# AI Web Application - Machine Learning Prediction Service

A full-stack web application for deploying and serving machine learning models with a modern React frontend and FastAPI backend. This project demonstrates production-ready ML model deployment, RESTful API design, and comprehensive testing practices.

## ğŸ¯ Project Overview

This application provides a complete ML model serving infrastructure with:
- **RESTful API** for model inference using FastAPI
- **Modern React Frontend** for interactive model predictions
- **PyTorch-based ML Models** with flexible architecture
- **Comprehensive Testing** (84% backend coverage, full frontend tests)
- **Docker Support** for containerized deployment
- **Production-ready** error handling and validation

## ğŸš€ Features

- **ML Model Serving**: Deploy and serve PyTorch models via REST API
- **Interactive UI**: React-based frontend for real-time predictions
- **Model Registry**: Manage multiple models with versioning support
- **API Documentation**: Auto-generated OpenAPI/Swagger documentation
- **Comprehensive Testing**: Unit, integration, and E2E tests
- **Error Handling**: Robust error handling with clear user feedback
- **CORS Support**: Configured for cross-origin requests
- **Hot Reload**: Development-friendly with auto-reload

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **PyTorch** - Deep learning framework
- **Pydantic** - Data validation
- **Poetry** - Dependency management
- **Pytest** - Testing framework
- **Uvicorn** - ASGI server

### Frontend
- **React 19** - UI library
- **TypeScript** - Type-safe JavaScript
- **Vite** - Build tool and dev server
- **Vitest** - Testing framework
- **React Testing Library** - Component testing

### DevOps
- **Docker** - Containerization
- **Docker Compose** - Multi-container orchestration
- **Git** - Version control

## ğŸ“ Project Structure

```
ai_webapp/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/          # API endpoints
â”‚   â”‚   â”œâ”€â”€ ml/           # ML models and inference
â”‚   â”‚   â”œâ”€â”€ models/       # Pydantic schemas
â”‚   â”‚   â””â”€â”€ main.py       # FastAPI application
â”‚   â”œâ”€â”€ tests/            # Backend tests
â”‚   â””â”€â”€ pyproject.toml    # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx       # Main React component
â”‚   â”‚   â””â”€â”€ test/         # Frontend tests
â”‚   â””â”€â”€ package.json      # Node dependencies
â”œâ”€â”€ docker-compose.yml    # Docker orchestration
â”œâ”€â”€ TESTING_GUIDE.md      # Comprehensive testing docs
â”œâ”€â”€ RUN_LOCALLY.md        # Local development guide
â””â”€â”€ README.md             # This file
```

## ğŸƒ Quick Start

### Prerequisites

- Python 3.12+
- Node.js 18+
- Poetry (`pip install poetry`)
- Docker (optional)

### Option 1: Local Development

**Backend:**
```bash
cd backend
poetry install
poetry shell
uvicorn app.main:app --reload
```

**Frontend:**
```bash
cd frontend
npm install
npm run dev
```

Access:
- Frontend: http://localhost:5173
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

### Option 2: Docker

```bash
docker-compose up --build
```

Access:
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000

## ğŸ§ª Testing

### Run All Tests

```bash
./test-all.sh
```

### Backend Tests

```bash
cd backend
poetry run pytest
poetry run pytest --cov=app  # With coverage
```

**Coverage: 84%** (10/10 tests passing)

### Frontend Tests

```bash
cd frontend
npm test -- --run
```

**Coverage: 7/7 tests passing**

See [TESTING_GUIDE.md](./TESTING_GUIDE.md) for detailed testing documentation.

## ğŸ“¡ API Endpoints

### Health Check
```bash
GET /health
```

### List Models
```bash
GET /api/models/
```

### Model Info
```bash
GET /api/models/{model_name}
```

### Prediction
```bash
POST /api/predict/
Content-Type: application/json

{
  "inputs": [1.0, 2.0, 3.0, 4.0],
  "model_name": "base"
}
```

Interactive API documentation available at `/docs` when backend is running.

## ğŸ—ï¸ Architecture

### Backend Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚  â† REST API Layer
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ API Routes  â”‚  â† Endpoint Handlers
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ ML Registry â”‚  â† Model Management
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  Inference  â”‚  â† Prediction Logic
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   PyTorch   â”‚  â† Model Execution
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Frontend Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React     â”‚  â† UI Components
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   Vite      â”‚  â† Dev Server & Build
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   Proxy     â”‚  â† API Requests
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI    â”‚  â† Backend API
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Configuration

### Backend

- Python version: 3.12+
- Dependencies managed via Poetry
- Environment variables: None required (can be added for production)

### Frontend

- Node.js version: 18+
- Dependencies managed via npm
- Vite proxy configured for `/api` â†’ `http://localhost:8000`

## ğŸ“Š Model Architecture

The default model (`RegressionNet`) is a feedforward neural network:

```
Input (4 features)
    â†“
Linear(4 â†’ 64) + ReLU
    â†“
Linear(64 â†’ 64) + ReLU
    â†“
Linear(64 â†’ 1)
    â†“
Output (prediction)
```

Models can be easily extended or replaced in `backend/app/ml/model.py`.

## ğŸš¢ Deployment

### Docker Deployment

```bash
docker-compose up -d
```

### Production Considerations

- Add environment variables for configuration
- Set up proper logging
- Configure reverse proxy (nginx)
- Add authentication/authorization
- Set up monitoring and alerting
- Use production-grade ASGI server (Gunicorn + Uvicorn workers)

## ğŸ“š Documentation

- [Testing Guide](./TESTING_GUIDE.md) - Comprehensive testing documentation
- [Run Locally](./RUN_LOCALLY.md) - Detailed local development setup
- [Quick Start](./QUICK_START.md) - Quick reference guide
- [API Documentation](http://localhost:8000/docs) - Interactive API docs (when running)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

See [LICENSE](./LICENSE) file for details.

## ğŸ“ Academic/Research Use

This project demonstrates:
- **ML Model Deployment**: Production-ready model serving
- **Software Engineering**: Clean architecture, testing, documentation
- **Full-Stack Development**: Modern web technologies
- **DevOps Practices**: Docker, CI/CD ready

Suitable for:
- Computer Vision research projects
- ML model deployment studies
- Full-stack development portfolios
- Software engineering demonstrations

## ğŸ”® Future Enhancements

- [ ] Model training pipeline
- [ ] Model versioning system
- [ ] Batch prediction support
- [ ] Authentication and authorization
- [ ] Model performance monitoring
- [ ] A/B testing framework
- [ ] CI/CD pipeline
- [ ] Kubernetes deployment
- [ ] Model explainability features

## ğŸ‘¤ Author

[Your Name]

## ğŸ™ Acknowledgments

- FastAPI for the excellent web framework
- PyTorch for the ML framework
- React team for the UI library

---

â­ If you find this project useful, please consider giving it a star!
